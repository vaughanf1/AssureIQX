---
phase: 03-splits-and-dataset-loader
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/data/split_utils.py
  - scripts/split.py
autonomous: true

must_haves:
  truths:
    - "Running `make split` produces 6 CSV manifests in data/splits/ (stratified_{train,val,test}.csv and center_{train,val,test}.csv)"
    - "No image_id appears in more than one split within the same strategy"
    - "Class proportions are preserved in stratified splits (each split has roughly 50.1% Normal, 40.7% Benign, 9.1% Malignant)"
    - "All 21 exact duplicate pairs land on the same side of every split"
    - "Leakage risk from same-lesion multi-angle images is documented in split script console output"
    - "Malignant count in every split is non-trivial (>0)"
  artifacts:
    - path: "src/data/split_utils.py"
      provides: "Pure split functions: derive_label, compute_duplicate_groups, stratified_split, center_holdout_split, save_split_csv"
      exports: ["derive_label", "compute_duplicate_groups", "stratified_split", "center_holdout_split", "save_split_csv"]
    - path: "scripts/split.py"
      provides: "CLI entry point that loads config, calls split_utils, writes CSVs, prints summary"
    - path: "data/splits/stratified_train.csv"
      provides: "Stratified training split manifest"
      contains: "image_id,split,label"
    - path: "data/splits/center_train.csv"
      provides: "Center-holdout training split manifest"
      contains: "image_id,split,label"
  key_links:
    - from: "scripts/split.py"
      to: "src/data/split_utils.py"
      via: "import and function calls"
      pattern: "from src\\.data\\.split_utils import"
    - from: "scripts/split.py"
      to: "src/utils/config.py"
      via: "load_config for YAML config"
      pattern: "load_config"
    - from: "src/data/split_utils.py"
      to: "data_raw/dataset.csv"
      via: "pd.read_csv for metadata"
      pattern: "pd\\.read_csv"
    - from: "src/data/split_utils.py"
      to: "data_raw/images/"
      via: "imagehash.phash for duplicate detection"
      pattern: "imagehash\\.phash"
---

<objective>
Implement the dual split strategy (stratified 70/15/15 and center-holdout) with duplicate-aware grouping and generate reproducible CSV manifests.

Purpose: Splits are the foundation of all downstream evaluation. Without correct, leakage-free splits, training and evaluation results are meaningless. The dual strategy enables both standard ML evaluation (stratified) and clinically meaningful generalization testing (center-holdout).

Output: 6 CSV split manifests in data/splits/, split utility module with pure functions, working `make split` command.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-splits-and-dataset-loader/03-RESEARCH.md

@configs/default.yaml
@scripts/split.py
@src/data/split_utils.py
@src/utils/config.py
@src/utils/reproducibility.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement split utility functions</name>
  <files>src/data/split_utils.py</files>
  <action>
Replace the docstring-only stub in src/data/split_utils.py with the complete split utilities module containing these functions:

1. **derive_label(row: pd.Series) -> str**: Derive 3-class label from binary columns in dataset.csv. Logic: if row["malignant"] == 1 -> "Malignant", elif row["benign"] == 1 -> "Benign", else -> "Normal". This matches the label derivation from the dataset spec (02-02).

2. **compute_duplicate_groups(images_dir: Path, image_ids: list[str]) -> dict[str, int]**: Compute perceptual hash for each image using imagehash.phash(img, hash_size=8). Group images with identical hashes (distance=0). Return a mapping of image_id -> group_id. Log the number of duplicate groups found. Use PIL Image.open for loading. This takes ~30 seconds on 3,746 images -- print progress indication.

3. **stratified_split(df, train_ratio=0.70, val_ratio=0.15, test_ratio=0.15, seed=42, label_col="label", group_col="dup_group") -> tuple[DataFrame, DataFrame, DataFrame]**:
   - Assert ratios sum to 1.0 (within epsilon 1e-6)
   - Handle duplicate groups: for each group with >1 member, keep only the first member for the split decision, then assign all members to the same split
   - Two-step train_test_split: first split 70/30 (train vs remainder), then split remainder 50/50 (val vs test). Both calls use stratify=df[label_col] and random_state=seed
   - After split, reassign duplicate partners to same split as their representative
   - Add "split" column with values "train", "val", "test"
   - Return (df_train, df_val, df_test)

4. **center_holdout_split(df, train_centers=[1], test_centers=[2, 3], val_ratio=0.15, seed=42, label_col="label", group_col="dup_group") -> tuple[DataFrame, DataFrame, DataFrame]**:
   - Filter df by center column: train_centers -> train+val, test_centers -> test
   - Handle duplicates same way as stratified (group members stay together)
   - Within train+val: use train_test_split with stratify to split into train/val. Val fraction = val_ratio / (1.0 - len(test)/len(total)) to keep val proportionally sized
   - Actually simpler: use 15% of Center 1 images as val (val_fraction = 0.15 / 0.85 = ~0.176 of Center 1 data). Use val_ratio directly relative to the trainval pool: test_size = val_ratio / (train_ratio + val_ratio) where train_ratio = 1.0 - val_ratio - (len(test)/len(total))... Better: just use val_ratio as fraction of Center 1 data. So test_size = val_ratio for the train_test_split on Center 1 data. This gives ~15% of Center 1 as val, ~85% as train.
   - Wait -- the research recommends: val_fraction = val_ratio / (1.0 - (len(df_test) / len(df))). But this is overcomplicating it. Simpler approach: just do train_test_split(df_trainval, test_size=val_ratio, stratify=..., random_state=seed). This gives 85/15 within Center 1. This is the research recommendation ("Use 15% of Center 1's images as validation").
   - Add "split" column
   - Return (df_train, df_val, df_test)

5. **save_split_csv(df, split_name, strategy, output_dir) -> Path**: Save DataFrame with columns [image_id, split, label] to output_dir/{strategy}_{split_name}.csv. Return the file path.

Important implementation details:
- Use `from __future__ import annotations` at the top
- Import pandas, numpy, imagehash, PIL.Image, Path, train_test_split, defaultdict, logging
- Use logging.getLogger(__name__) for all output
- Column name for center is "center" (lowercase, no spaces) in dataset.csv
- image_id column in dataset.csv contains the actual filename with extension (.jpeg or .jpg) -- use as-is
- The "tumor" column: tumor=0 means Normal (no tumor), tumor=1 means has tumor (then check benign/malignant)
  </action>
  <verify>
Run `python -c "from src.data.split_utils import derive_label, compute_duplicate_groups, stratified_split, center_holdout_split, save_split_csv; print('All imports OK')"` from the project root.
  </verify>
  <done>src/data/split_utils.py exports all 5 functions, imports succeed without errors, functions have proper type hints and docstrings.</done>
</task>

<task type="auto">
  <name>Task 2: Implement split script and generate manifests</name>
  <files>scripts/split.py</files>
  <action>
Replace the NotImplementedError in scripts/split.py with the complete split logic. The script already has argparse, load_config, and set_seed wired up. Replace everything after set_seed() with:

1. **Load dataset.csv**: Read data_raw/dataset.csv with pandas. Derive the "label" column using derive_label() applied row-by-row. Verify total count matches expected_image_count from config (3746). Print class distribution.

2. **Compute duplicate groups**: Call compute_duplicate_groups(images_dir, image_ids). Add a "dup_group" column to the DataFrame. Log the number of exact duplicate groups found (should find 21 pairs = 21 groups of size 2). Print a leakage risk warning:
   ```
   WARNING: 21 exact duplicate image pairs detected.
   Duplicate groups are forced to the same split side to prevent data leakage.
   NOTE: No patient_id column exists in dataset. Same-lesion multi-angle images
   cannot be reliably grouped. This is a known leakage risk documented in the
   audit report (docs/data_audit_report.md). Proxy grouping (center+age+gender)
   produces 295 groups which is too coarse for reliable patient-level splitting.
   ```

3. **Create output directory**: Ensure data/splits/ exists (Path.mkdir(parents=True, exist_ok=True)). Use cfg["data"]["splits_dir"] from config.

4. **Run stratified split**: Call stratified_split() with config params (train_ratio from cfg["data"]["train_split"], val_ratio from cfg["data"]["val_split"], test_ratio from cfg["data"]["test_split"], seed from cfg["seed"]). Save 3 CSVs using save_split_csv with strategy="stratified". Print per-split class distribution table.

5. **Run center-holdout split**: Call center_holdout_split() with train_centers=[1], test_centers=[2, 3], val_ratio from config, seed from config. Save 3 CSVs with strategy="center". Print per-split class distribution table including center breakdown.

6. **Validation checks** (run after both splits, print results):
   - No image_id appears in more than one split within same strategy (assert using set intersection)
   - All 3,746 images are accounted for in each strategy
   - Malignant count > 0 in every split
   - Every duplicate pair has both members in the same split
   - Print summary: total images, splits per strategy, class balance per split

7. **Print leakage documentation**: At the end of the script output, print a clear section documenting the leakage risk:
   ```
   === LEAKAGE RISK DOCUMENTATION ===
   - No patient_id available: cannot guarantee train/test images are from different patients
   - 21 exact duplicate pairs: grouped to same split (MITIGATED)
   - Same-lesion multi-angle images: NOT mitigated (no reliable grouping metadata)
   - Proxy grouping (center+age+gender) too coarse: 295 groups for 3746 images
   - Recommendation: treat evaluation metrics as optimistic upper bounds
   ```

Import from src.data.split_utils at the top of main() or at module level after the sys.path.insert.
  </action>
  <verify>
Run `python scripts/split.py --config configs/default.yaml` from the project root. Verify:
1. Script completes without error
2. 6 CSV files exist in data/splits/
3. Run `wc -l data/splits/*.csv` -- each file should have a header + expected row counts (stratified: ~2622 train, ~562 val, ~562 test; center: varies)
4. Run `head -2 data/splits/stratified_train.csv` -- should show "image_id,split,label" header with correct data
5. Run `make split` -- should produce same result (idempotent with same seed)
  </verify>
  <done>
Running `make split` produces 6 CSV manifests in data/splits/. No image_id appears in more than one split within either strategy. Class proportions are preserved in stratified splits. All 21 duplicate pairs land on the same split side. Leakage risk is documented in console output. Malignant count > 0 in every split.
  </done>
</task>

</tasks>

<verification>
1. `make split` runs without errors and produces 6 CSV files in data/splits/
2. Each CSV has exactly 3 columns: image_id, split, label
3. Stratified split counts sum to 3746 (total dataset size)
4. Center split: test set contains only Centers 2+3, train+val contain only Center 1
5. No duplicate image crosses a split boundary (verify by checking phash groups)
6. Class proportions in stratified splits are within 2% of original distribution
7. Script is idempotent: running twice with same seed produces identical CSVs
</verification>

<success_criteria>
- 6 CSV manifest files exist in data/splits/ with correct format
- Stratified split preserves class proportions across train/val/test
- Center-holdout correctly separates Center 1 (train/val) from Centers 2+3 (test)
- 21 duplicate pairs are grouped to same split in both strategies
- Leakage risk documentation appears in script output
- `make split` works end-to-end
</success_criteria>

<output>
After completion, create `.planning/phases/03-splits-and-dataset-loader/03-01-SUMMARY.md`
</output>
