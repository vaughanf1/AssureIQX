---
phase: 03-splits-and-dataset-loader
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/data/transforms.py
  - src/data/dataset.py
  - src/data/__init__.py
autonomous: true

must_haves:
  truths:
    - "BTXRDDataset loads images from split manifests and returns (tensor, label_index) tuples"
    - "Tensors have shape (3, 224, 224) with float32 dtype"
    - "ImageNet normalization is applied (values roughly in [-2.5, 2.5] range)"
    - "Training transforms include CLAHE, HorizontalFlip, Rotate(+/-15), Resize(224), Normalize"
    - "Val/test transforms include only Resize(224) and Normalize (deterministic)"
    - "CLAHE is applied BEFORE Normalize (on uint8 input)"
    - "DataLoader produces batches of shape (batch_size, 3, 224, 224)"
  artifacts:
    - path: "src/data/transforms.py"
      provides: "Augmentation pipelines: get_train_transforms, get_val_transforms, get_test_transforms"
      exports: ["get_train_transforms", "get_val_transforms", "get_test_transforms", "IMAGENET_MEAN", "IMAGENET_STD"]
    - path: "src/data/dataset.py"
      provides: "BTXRDDataset class with lazy image loading and albumentations integration"
      exports: ["BTXRDDataset", "CLASS_TO_IDX", "IDX_TO_CLASS", "create_dataloader"]
    - path: "src/data/__init__.py"
      provides: "Public API exports for the data package"
      exports: ["BTXRDDataset", "CLASS_TO_IDX", "IDX_TO_CLASS", "create_dataloader", "get_train_transforms", "get_val_transforms", "get_test_transforms"]
  key_links:
    - from: "src/data/dataset.py"
      to: "data/splits/*.csv"
      via: "pd.read_csv in __init__"
      pattern: "pd\\.read_csv"
    - from: "src/data/dataset.py"
      to: "data_raw/images/"
      via: "PIL Image.open in __getitem__"
      pattern: "Image\\.open"
    - from: "src/data/dataset.py"
      to: "src/data/transforms.py"
      via: "transform parameter accepts albumentations Compose"
      pattern: "self\\.transform"
    - from: "src/data/__init__.py"
      to: "src/data/dataset.py"
      via: "re-export BTXRDDataset and create_dataloader"
      pattern: "from src\\.data\\.dataset import"
---

<objective>
Implement the PyTorch Dataset class that loads BTXRD images from split manifests, and the albumentations augmentation pipelines for train/val/test modes.

Purpose: The Dataset and transforms are the bridge between raw data and the training loop. Getting the augmentation pipeline right (especially CLAHE ordering and ImageNet normalization) is critical -- subtle bugs here cause silent model degradation that only surfaces as poor metrics in Phase 5.

Output: Working BTXRDDataset class, train/val/test transform pipelines, DataLoader factory function, updated __init__.py with public exports.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-splits-and-dataset-loader/03-RESEARCH.md
@.planning/phases/03-splits-and-dataset-loader/03-01-SUMMARY.md

@configs/default.yaml
@src/data/transforms.py
@src/data/dataset.py
@src/data/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement augmentation pipelines and dataset class</name>
  <files>src/data/transforms.py, src/data/dataset.py, src/data/__init__.py</files>
  <action>
**File 1: src/data/transforms.py** -- Replace the docstring-only stub with the complete transforms module:

1. Import albumentations as A, from albumentations.pytorch import ToTensorV2
2. Define constants: IMAGENET_MEAN = (0.485, 0.456, 0.406), IMAGENET_STD = (0.229, 0.224, 0.225)
3. **get_train_transforms(image_size: int = 224) -> A.Compose**: Training augmentation pipeline. Order is critical (CLAHE must be BEFORE Normalize because CLAHE requires uint8 input):
   - A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0) -- always applied, contrast enhancement for radiographs
   - A.HorizontalFlip(p=0.5)
   - A.Rotate(limit=15, border_mode=0, fill=0, p=0.5) -- +/-15 degrees, black fill for borders
   - A.Resize(height=image_size, width=image_size)
   - A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
   - ToTensorV2()

4. **get_val_transforms(image_size: int = 224) -> A.Compose**: Deterministic preprocessing only:
   - A.Resize(height=image_size, width=image_size)
   - A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
   - ToTensorV2()

5. **get_test_transforms = get_val_transforms** -- alias, test transforms are identical to val transforms

Include docstrings explaining the ordering rationale. Use `from __future__ import annotations`.

**File 2: src/data/dataset.py** -- Replace the docstring-only stub with the complete dataset module:

1. Imports: numpy, pandas, torch, Path, PIL.Image, torch.utils.data.Dataset, torch.utils.data.DataLoader, logging
2. Define constants:
   - CLASS_TO_IDX = {"Normal": 0, "Benign": 1, "Malignant": 2}
   - IDX_TO_CLASS = {v: k for k, v in CLASS_TO_IDX.items()}

3. **BTXRDDataset(Dataset)** class:
   - __init__(self, manifest_csv: str | Path, images_dir: str | Path, transform=None):
     - Read manifest CSV with pd.read_csv
     - Store images_dir as Path
     - Store transform
     - Validate required columns exist: {"image_id", "label"} -- raise ValueError if missing
     - Validate all labels are in CLASS_TO_IDX -- raise ValueError if unknown labels found
   - __len__(self) -> int: return len(self.df)
   - __getitem__(self, idx: int) -> tuple[torch.Tensor, int]:
     - Get row from self.df.iloc[idx]
     - Extract image_id and label_str
     - Convert label_str to label_idx via CLASS_TO_IDX
     - Load image: Image.open(self.images_dir / image_id).convert("RGB") -- handles both .jpeg and .jpg, converts grayscale to RGB
     - Convert to numpy array: np.array(image) -- produces HWC uint8 ndarray
     - Apply transform if not None: transformed = self.transform(image=image); image = transformed["image"]
     - Return (image, label_idx)
   - class_counts property: return self.df["label"].value_counts().to_dict()
   - labels property: return [CLASS_TO_IDX[l] for l in self.df["label"].tolist()] -- useful for computing class weights in Phase 4

4. **create_dataloader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True) -> DataLoader**: Factory function wrapping DataLoader with standard settings. Set drop_last=False.

Use `from __future__ import annotations` and logging.getLogger(__name__).

**File 3: src/data/__init__.py** -- Update to export the public API:

```python
"""Data loading, transforms, and split utilities for BTXRD dataset."""

from src.data.dataset import BTXRDDataset, CLASS_TO_IDX, IDX_TO_CLASS, create_dataloader
from src.data.transforms import (
    get_train_transforms,
    get_val_transforms,
    get_test_transforms,
    IMAGENET_MEAN,
    IMAGENET_STD,
)

__all__ = [
    "BTXRDDataset",
    "CLASS_TO_IDX",
    "IDX_TO_CLASS",
    "create_dataloader",
    "get_train_transforms",
    "get_val_transforms",
    "get_test_transforms",
    "IMAGENET_MEAN",
    "IMAGENET_STD",
]
```
  </action>
  <verify>
Run all of these from the project root:

1. Import check:
```bash
python -c "from src.data import BTXRDDataset, get_train_transforms, get_val_transforms, create_dataloader, CLASS_TO_IDX; print('All imports OK')"
```

2. Transform shape check:
```bash
python -c "
from src.data.transforms import get_train_transforms, get_val_transforms
import numpy as np
t_train = get_train_transforms(224)
t_val = get_val_transforms(224)
fake = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
out_train = t_train(image=fake)['image']
out_val = t_val(image=fake)['image']
assert out_train.shape == (3, 224, 224), f'Train shape wrong: {out_train.shape}'
assert out_val.shape == (3, 224, 224), f'Val shape wrong: {out_val.shape}'
assert out_train.dtype.is_floating_point, 'Train not float'
print(f'Train: {out_train.shape}, range [{out_train.min():.2f}, {out_train.max():.2f}]')
print(f'Val: {out_val.shape}, range [{out_val.min():.2f}, {out_val.max():.2f}]')
print('Transform checks PASSED')
"
```

3. Dataset end-to-end check (requires 03-01 split manifests):
```bash
python -c "
from src.data import BTXRDDataset, get_val_transforms, create_dataloader
import torch
ds = BTXRDDataset('data/splits/stratified_val.csv', 'data_raw/images', transform=get_val_transforms(224))
print(f'Dataset size: {len(ds)}')
img, label = ds[0]
assert img.shape == (3, 224, 224), f'Shape wrong: {img.shape}'
assert img.dtype == torch.float32, f'Type wrong: {img.dtype}'
assert label in {0, 1, 2}, f'Label wrong: {label}'
assert img.min() > -5.0 and img.max() < 5.0, f'Normalization wrong: [{img.min():.2f}, {img.max():.2f}]'
dl = create_dataloader(ds, batch_size=4, shuffle=False, num_workers=0)
batch_imgs, batch_labels = next(iter(dl))
assert batch_imgs.shape == (4, 3, 224, 224), f'Batch shape wrong: {batch_imgs.shape}'
print(f'Single: shape={img.shape}, dtype={img.dtype}, range=[{img.min():.2f}, {img.max():.2f}], label={label}')
print(f'Batch: shape={batch_imgs.shape}')
print(f'Class counts: {ds.class_counts}')
print('Dataset checks PASSED')
"
```
  </verify>
  <done>
BTXRDDataset loads images from split manifests and returns correctly shaped tensors (3, 224, 224) with float32 dtype and ImageNet normalization. Training transforms apply CLAHE, HorizontalFlip, Rotate(+/-15), Resize(224), Normalize. Val/test transforms apply only Resize and Normalize. DataLoader produces batches of (batch_size, 3, 224, 224). All exports are available from src.data.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.data import BTXRDDataset, get_train_transforms, get_val_transforms"` -- imports succeed
2. Train transforms produce (3, 224, 224) float32 tensors from uint8 input with CLAHE applied
3. Val/test transforms produce (3, 224, 224) float32 tensors with only resize and normalize
4. BTXRDDataset loads from split CSV and returns (tensor, label_idx) tuples
5. DataLoader produces batches of correct shape (batch_size, 3, 224, 224)
6. class_counts property returns per-class sample counts
7. labels property returns list of int label indices
</verification>

<success_criteria>
- BTXRDDataset loads any split manifest CSV and returns correct (tensor, label) pairs
- Tensor shape is (3, 224, 224) with float32 dtype for all modes
- Training pipeline includes CLAHE -> HorizontalFlip -> Rotate -> Resize -> Normalize -> ToTensorV2
- Val/test pipeline includes only Resize -> Normalize -> ToTensorV2
- DataLoader batching works correctly with standard settings
- All exports available from src.data package
</success_criteria>

<output>
After completion, create `.planning/phases/03-splits-and-dataset-loader/03-02-SUMMARY.md`
</output>
