---
phase: 06-explainability-and-inference
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - scripts/infer.py
autonomous: true

must_haves:
  truths:
    - "Running `python scripts/infer.py --image path/to/image.jpg --checkpoint path/to/best.pt` outputs class prediction, softmax confidences, and Grad-CAM overlay PNG"
    - "Running `python scripts/infer.py --input-dir path/to/images/` processes all images in directory and outputs predictions for each"
    - "Grad-CAM overlay PNG is saved alongside each input image (or in specified output directory)"
    - "Console output shows class name, confidence scores for all 3 classes, and path to saved overlay"
  artifacts:
    - path: "scripts/infer.py"
      provides: "Single-image and batch inference CLI with Grad-CAM overlay generation"
      min_lines: 100
  key_links:
    - from: "scripts/infer.py"
      to: "src/explainability/gradcam.py"
      via: "imports generate_gradcam, denormalize_tensor, create_overlay"
      pattern: "from src\\.explainability\\.gradcam import"
    - from: "scripts/infer.py"
      to: "src/models/factory.py"
      via: "load_checkpoint, create_model, get_device"
      pattern: "from src\\.models\\.factory import"
    - from: "scripts/infer.py"
      to: "src/data/transforms.py"
      via: "get_test_transforms for preprocessing"
      pattern: "from src\\.data\\.transforms import"
---

<objective>
Implement the single-image and batch inference CLI script (INFR-01, INFR-02).

Purpose: Provide a straightforward command-line tool for clinicians and developers to run predictions on arbitrary radiograph images, producing class predictions with confidence scores and visual Grad-CAM overlays that show where the model attends.

Output:
- `scripts/infer.py` -- complete CLI script supporting `--image` (single), `--input-dir` (batch), `--checkpoint`, and `--output-dir` arguments, producing predictions with confidence scores printed to console and Grad-CAM overlay PNGs saved to disk
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-explainability-and-inference/06-RESEARCH.md

# Plan 06-01 creates the utility functions this script uses
@.planning/phases/06-explainability-and-inference/06-01-PLAN.md

# Key source files
@src/explainability/gradcam.py   -- generate_gradcam, denormalize_tensor, create_overlay (from 06-01)
@src/models/factory.py           -- create_model, load_checkpoint, get_device
@src/data/transforms.py          -- get_test_transforms, IMAGENET_MEAN, IMAGENET_STD
@scripts/infer.py                -- existing stub with argparse skeleton
@configs/default.yaml            -- inference.default_checkpoint config
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement scripts/infer.py single-image and batch inference</name>
  <files>scripts/infer.py</files>
  <action>
Replace the `NotImplementedError` stub in `scripts/infer.py` with a complete inference script. Keep the existing argparse skeleton (--config, --override, --image, --input-dir) and ADD:
- `--checkpoint` argument (str, optional, default from config `inference.default_checkpoint`)
- `--output-dir` argument (str, optional, default "results/inference/")
- `--no-gradcam` flag (store_true) to skip Grad-CAM overlay generation for faster inference

**Single-image mode (`--image`):**

1. Validate the image path exists. Support common extensions: .jpg, .jpeg, .png, .bmp, .tiff.
2. Load checkpoint from `--checkpoint` (or config default). Use `load_checkpoint`, `create_model`, `model.load_state_dict`, `model.to(device)`, `model.eval()`.
3. Load image with `PIL.Image.open(path).convert("RGB")`, convert to numpy array.
4. Apply `get_test_transforms(image_size)` from config. Unsqueeze to batch dim.
5. Run forward pass with `torch.no_grad()` to get logits. Apply `F.softmax(logits, dim=1)` for confidence scores.
6. Extract predicted class, confidence scores for all 3 classes.
7. Unless `--no-gradcam`: Generate Grad-CAM targeting the predicted class using `generate_gradcam` from `src.explainability.gradcam`. Denormalize tensor, create overlay using `create_overlay`.
8. Save Grad-CAM overlay PNG to output directory: `{output_dir}/{stem}_gradcam.png`. Use `PIL.Image.fromarray(overlay).save()` (NOT cv2.imwrite).
9. Print to console:
   ```
   Image: {filename}
   Prediction: {class_name} (confidence: {prob:.3f})
   Scores: Normal={:.3f}, Benign={:.3f}, Malignant={:.3f}
   Grad-CAM overlay: {output_path}
   ```

**Batch mode (`--input-dir`):**

1. Glob all image files in directory matching common extensions (*.jpg, *.jpeg, *.png, *.bmp, *.tiff).
2. Validate at least 1 image found. Print count.
3. Process each image individually using the same single-image pipeline (load, transform, predict, gradcam, save).
4. Collect results into a list of dicts: `{image_name, prediction, confidence, scores: {Normal, Benign, Malignant}}`.
5. Save batch results to `{output_dir}/batch_results.json`.
6. Print summary table to console showing image name, prediction, and confidence for each.

**Argument validation:**
- Exactly one of `--image` or `--input-dir` must be provided. If neither or both, print error and exit.
- If `--checkpoint` not provided, use `cfg["inference"]["default_checkpoint"]`. If that checkpoint file doesn't exist, print helpful error.

**Critical details:**
- Use `get_test_transforms` (deterministic, no augmentation) -- NEVER train transforms for inference.
- Softmax applied exactly once (model outputs raw logits).
- Do NOT wrap GradCAM calls in `torch.no_grad()` -- it needs gradients. But DO use `torch.no_grad()` for the initial prediction pass.
- Class names from `ckpt["class_names"]` (not hardcoded).
- The `generate_gradcam` function from 06-01 takes `(model, input_tensor, target_class_idx)`. The input_tensor must be on the correct device with batch dimension.
- Create output directory if it doesn't exist.
  </action>
  <verify>
Test single-image mode:
```bash
python scripts/infer.py --image data_raw/images/IMG000001.jpeg --checkpoint checkpoints/best_stratified.pt
```
Confirm: prints prediction with confidence scores, saves Grad-CAM overlay to results/inference/.

Test batch mode:
```bash
mkdir -p /tmp/test_batch && cp data_raw/images/IMG000001.jpeg data_raw/images/IMG000002.jpeg data_raw/images/IMG000003.jpeg /tmp/test_batch/
python scripts/infer.py --input-dir /tmp/test_batch --checkpoint checkpoints/best_stratified.pt
```
Confirm: processes 3 images, saves 3 overlays + batch_results.json, prints summary table.

Test error handling:
```bash
python scripts/infer.py 2>&1 | grep -i "error\|usage"
```
Confirm: prints error about requiring --image or --input-dir.
  </verify>
  <done>
`python scripts/infer.py --image path/to/image.jpg --checkpoint checkpoints/best_stratified.pt` outputs class prediction with 3-class softmax confidences and saves a Grad-CAM overlay PNG. Batch mode via `--input-dir` processes all images in a directory and saves predictions as JSON. Both modes follow the exact CLI interface specified in Phase 6 success criteria 4 and 5.
  </done>
</task>

</tasks>

<verification>
1. `python scripts/infer.py --image data_raw/images/IMG000001.jpeg` completes and prints prediction
2. `ls results/inference/` shows IMG000001_gradcam.png
3. `python scripts/infer.py --input-dir data_raw/images/ --output-dir /tmp/infer_test` processes images and creates batch_results.json (note: this will be slow on full image dir; test with a subset)
4. `python scripts/infer.py` (no args) prints usage error
5. `python scripts/infer.py --image nonexistent.jpg` prints file-not-found error
</verification>

<success_criteria>
- INFR-01: Single-image inference with class prediction, softmax confidences, and Grad-CAM overlay PNG
- INFR-02: Batch inference mode processing a directory of images with JSON results output
- CLI interface matches Phase 6 success criteria: `--image`, `--checkpoint`, `--input-dir` arguments
- Reuses generate_gradcam, denormalize_tensor, create_overlay from src/explainability/gradcam.py (06-01)
</success_criteria>

<output>
After completion, create `.planning/phases/06-explainability-and-inference/06-02-SUMMARY.md`
</output>
