---
phase: 04-model-training
plan: 03
type: execute
wave: 3
depends_on: ["04-02"]
files_modified:
  - checkpoints/best_stratified.pt
  - checkpoints/final_stratified.pt
  - checkpoints/best_center.pt
  - checkpoints/final_center.pt
  - results/stratified/training_log.csv
  - results/stratified/loss_curve.png
  - results/stratified/recall_curve.png
  - results/center_holdout/training_log.csv
  - results/center_holdout/loss_curve.png
  - results/center_holdout/recall_curve.png
autonomous: true

must_haves:
  truths:
    - "Stratified training converges: val_loss decreases over epochs and early stopping triggers or max epochs reached"
    - "Center-holdout training converges: val_loss decreases over epochs"
    - "Malignant class is NOT collapsed: val_recall_malignant > 0 in the final epoch for both splits"
    - "Checkpoints load successfully and produce valid 3-class softmax outputs"
    - "Training logs contain complete epoch records with all metric columns"
    - "Loss curve PNGs show convergence patterns (not flat lines or NaN)"
  artifacts:
    - path: "checkpoints/best_stratified.pt"
      provides: "Best model checkpoint for stratified split (lowest val_loss)"
    - path: "checkpoints/final_stratified.pt"
      provides: "Final epoch checkpoint for stratified split"
    - path: "checkpoints/best_center.pt"
      provides: "Best model checkpoint for center-holdout split (lowest val_loss)"
    - path: "checkpoints/final_center.pt"
      provides: "Final epoch checkpoint for center-holdout split"
    - path: "results/stratified/training_log.csv"
      provides: "Epoch-level training metrics for stratified split"
      contains: "epoch,train_loss,val_loss"
    - path: "results/center_holdout/training_log.csv"
      provides: "Epoch-level training metrics for center-holdout split"
      contains: "epoch,train_loss,val_loss"
    - path: "results/stratified/loss_curve.png"
      provides: "Loss convergence plot for stratified split"
    - path: "results/center_holdout/loss_curve.png"
      provides: "Loss convergence plot for center-holdout split"
  key_links:
    - from: "checkpoints/best_stratified.pt"
      to: "scripts/train.py"
      via: "save_checkpoint called when val_loss improves"
      pattern: "save_checkpoint"
    - from: "results/stratified/training_log.csv"
      to: "scripts/train.py"
      via: "save_training_log called after training completes"
      pattern: "save_training_log"
---

<objective>
Train the EfficientNet-B0 classifier on both split strategies (stratified and center-holdout), producing checkpoints and training logs that prove convergence and confirm the Malignant class is not collapsed.

Purpose: This is the culmination of Phase 4 -- it produces the actual trained model artifacts that Phase 5 (evaluation) and Phase 6 (Grad-CAM/inference) consume. Without trained checkpoints, no downstream work is possible.

Output: 4 checkpoint files, 2 training log CSVs, 4 plot PNGs (loss + recall for each split).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-model-training/04-RESEARCH.md
@.planning/phases/04-model-training/04-01-SUMMARY.md
@.planning/phases/04-model-training/04-02-SUMMARY.md
@configs/default.yaml
@scripts/train.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Train on stratified split and verify convergence</name>
  <files>
    checkpoints/best_stratified.pt
    checkpoints/final_stratified.pt
    results/stratified/training_log.csv
    results/stratified/loss_curve.png
    results/stratified/recall_curve.png
  </files>
  <action>
Run the training script on the stratified split:

```bash
python scripts/train.py --config configs/default.yaml --override training.split_strategy=stratified
```

This will train EfficientNet-B0 on the stratified train split (2,621 samples, ~82 batches at batch_size=32) with validation on the stratified val split. Training uses the default config: lr=0.001, epochs=50, patience=7, cosine scheduler.

**Expected behavior:**
- Training takes ~5-15 minutes on MPS (Apple Silicon), longer on CPU
- Early stopping may trigger before epoch 50
- val_loss should decrease initially then plateau
- Malignant recall should be > 0 throughout training (weighted loss prevents collapse)

**If training hangs at first batch** (macOS DataLoader issue): retry with `--override data.num_workers=0`

**After training completes, verify:**

1. Checkpoints exist and are loadable:
```python
import sys; sys.path.insert(0, '.')
import torch
from src.models import create_model, load_checkpoint

ckpt = load_checkpoint('checkpoints/best_stratified.pt')
print(f"Best checkpoint: epoch={ckpt['epoch']}, val_loss={ckpt['val_loss']:.4f}")
assert 'model_state_dict' in ckpt
assert 'optimizer_state_dict' in ckpt
assert 'config' in ckpt
assert ckpt['class_names'] == ['Normal', 'Benign', 'Malignant']
assert 'normalization' in ckpt

# Load into model and verify forward pass
model = create_model(ckpt['config'])
model.load_state_dict(ckpt['model_state_dict'])
model.eval()
x = torch.randn(1, 3, 224, 224)
with torch.no_grad():
    out = model(x)
probs = torch.softmax(out, dim=1)
print(f"Softmax output: {probs}")
assert probs.shape == (1, 3)
assert abs(probs.sum().item() - 1.0) < 1e-5
print("Checkpoint loads and produces valid 3-class softmax output")
```

2. Training log CSV exists and has correct columns:
```python
import pandas as pd
df = pd.read_csv('results/stratified/training_log.csv')
required_cols = ['epoch', 'train_loss', 'val_loss', 'val_acc', 'val_recall_normal', 'val_recall_benign', 'val_recall_malignant', 'lr']
for col in required_cols:
    assert col in df.columns, f"Missing column: {col}"
print(f"Training log: {len(df)} epochs, final val_loss={df['val_loss'].iloc[-1]:.4f}")
print(f"Final per-class recall: Normal={df['val_recall_normal'].iloc[-1]:.3f}, Benign={df['val_recall_benign'].iloc[-1]:.3f}, Malignant={df['val_recall_malignant'].iloc[-1]:.3f}")

# Confirm Malignant not collapsed
assert df['val_recall_malignant'].iloc[-1] > 0, "MALIGNANT CLASS COLLAPSED - recall is 0 in final epoch"
print("Malignant class NOT collapsed (recall > 0)")
```

3. Loss curve and recall curve PNGs exist:
```bash
ls -la results/stratified/loss_curve.png results/stratified/recall_curve.png
```
  </action>
  <verify>
All three checks above pass: (1) checkpoint loads and produces valid softmax, (2) training log has all columns and Malignant recall > 0, (3) PNG plots exist.
  </verify>
  <done>Stratified training complete. Checkpoints saved, training log shows convergence, Malignant recall > 0, loss/recall curves saved as PNG.</done>
</task>

<task type="auto">
  <name>Task 2: Train on center-holdout split and verify convergence</name>
  <files>
    checkpoints/best_center.pt
    checkpoints/final_center.pt
    results/center_holdout/training_log.csv
    results/center_holdout/loss_curve.png
    results/center_holdout/recall_curve.png
  </files>
  <action>
Run the training script on the center-holdout split:

```bash
python scripts/train.py --config configs/default.yaml --override training.split_strategy=center
```

This trains on Center 1 train split (2,499 samples, ~79 batches at batch_size=32) with validation on Center 1 val split. Same hyperparameters as stratified.

**Expected behavior:**
- Class weights will be slightly different from stratified (Normal=0.615, Benign=0.882, Malignant=4.165) due to different training set composition
- Convergence may look different from stratified (different data distribution)
- Malignant recall should still be > 0

**After training completes, run same verification as Task 1 but for center split:**

1. Load and verify `checkpoints/best_center.pt` -- forward pass produces valid softmax
2. Verify `results/center_holdout/training_log.csv` has all columns, Malignant recall > 0 in final epoch
3. Verify `results/center_holdout/loss_curve.png` and `results/center_holdout/recall_curve.png` exist

Then print a final comparison summary:
```python
import pandas as pd
strat = pd.read_csv('results/stratified/training_log.csv')
center = pd.read_csv('results/center_holdout/training_log.csv')
print("=== Training Comparison ===")
print(f"Stratified: {len(strat)} epochs, best val_loss={strat['val_loss'].min():.4f}")
print(f"  Final recall: Normal={strat['val_recall_normal'].iloc[-1]:.3f}, Benign={strat['val_recall_benign'].iloc[-1]:.3f}, Malignant={strat['val_recall_malignant'].iloc[-1]:.3f}")
print(f"Center: {len(center)} epochs, best val_loss={center['val_loss'].min():.4f}")
print(f"  Final recall: Normal={center['val_recall_normal'].iloc[-1]:.3f}, Benign={center['val_recall_benign'].iloc[-1]:.3f}, Malignant={center['val_recall_malignant'].iloc[-1]:.3f}")
```
  </action>
  <verify>
Same verification as Task 1 applied to center split: checkpoint loads with valid softmax, training log complete with Malignant recall > 0, PNGs exist. Comparison summary printed.
  </verify>
  <done>Both split strategies trained. 4 checkpoints, 2 training logs, 4 plots exist. Malignant recall > 0 for both. Phase 4 success criteria fully met.</done>
</task>

</tasks>

<verification>
Final Phase 4 verification after both tasks:

```bash
# 1. All checkpoint files exist
ls -la checkpoints/best_stratified.pt checkpoints/final_stratified.pt checkpoints/best_center.pt checkpoints/final_center.pt

# 2. All training logs exist with correct columns
python -c "
import pandas as pd
for split in ['stratified', 'center_holdout']:
    path = f'results/{split}/training_log.csv'
    df = pd.read_csv(path)
    assert 'val_recall_malignant' in df.columns
    assert df['val_recall_malignant'].iloc[-1] > 0, f'{split}: Malignant collapsed!'
    print(f'{split}: {len(df)} epochs, best_val_loss={df[\"val_loss\"].min():.4f}, final_malignant_recall={df[\"val_recall_malignant\"].iloc[-1]:.3f}')
print('ALL TRAINING LOGS VERIFIED')
"

# 3. All plots exist
ls -la results/stratified/loss_curve.png results/stratified/recall_curve.png results/center_holdout/loss_curve.png results/center_holdout/recall_curve.png

# 4. Checkpoint round-trip produces valid softmax
python -c "
import sys; sys.path.insert(0, '.')
import torch
from src.models import create_model, load_checkpoint

for name in ['best_stratified', 'best_center']:
    ckpt = load_checkpoint(f'checkpoints/{name}.pt')
    model = create_model(ckpt['config'])
    model.load_state_dict(ckpt['model_state_dict'])
    model.eval()
    with torch.no_grad():
        out = model(torch.randn(1, 3, 224, 224))
    probs = torch.softmax(out, dim=1)
    assert probs.shape == (1, 3)
    assert abs(probs.sum().item() - 1.0) < 1e-5
    print(f'{name}: valid 3-class softmax output')
print('ALL CHECKPOINTS VERIFIED')
"
```

All checks must pass.
</verification>

<success_criteria>
- 4 checkpoint files exist in checkpoints/ (best + final for each split)
- 2 training log CSVs with complete epoch records in results/
- 4 PNG plots (loss + recall for each split) in results/
- Malignant recall > 0 in final epoch for BOTH splits (class not collapsed)
- Checkpoints load and produce valid 3-class softmax outputs
- Training shows convergence (val_loss decreasing pattern, not flat or NaN)
</success_criteria>

<output>
After completion, create `.planning/phases/04-model-training/04-03-SUMMARY.md`
</output>
